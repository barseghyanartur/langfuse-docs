---
noindex: true
---

# Continuous technical documentation of Langfuse V3

Langfuse V3 is currently in development, see this [GitHub Discussion thread](https://github.com/orgs/langfuse/discussions/1902) for more information.

This document summarizes changes compared to v2 with regards to self-hosted deployments. While v3 is not released, these changes are unstable and can change.

## Reasoning

Langfuse has gained traction over the last months and so we are working on scaling the backend to handle more requests. On Langfuse Cloud, we gradually move to the more scalable backend and want to release it to self-hosters by the end of November. The new version contains two Docker containers, Postgres, Redis, S3, and Clickhouse.

### Why Clickhouse

In Langfuse v2, we stored all tracing data in Postgres. Postgres was an excellent choice initially due to its robustness, flexibility, and the extensive tooling available. However, we encountered challenges with Postgres as it struggled to handle high insert rates while simultaneously running low-latency analytical queries. Our users need to analyze trends, such as changes in the cost of their LLM calls over time, and drill down into specific traces with particular attributes. Additionally, we required a database that is free and easy to use for self-hosting users of different kinds. Some want to quickly try out Langfuse on their local machine, others have very high scalability requirements. Lastly, we want to do a database migration once as this is a very complex and time consuming project to pull off for the cloud product but also for our seld-hosting users.

We ended up with the following options:
- **Extend the Postgres runway**: With tools such as TimescaleDB, we could have extended the time we could remain on Postgres for our Cloud product. Also, many self-hosters would have appreciated this option as many do not have the scale requirements we have on the Cloud product. However, this comes with trade offs: First, not all of the Postgres extensions are available on AWS RDS which means that self-hosters would have to deploy the database themselves on an EC2 instance. Hence, self hosting would have become more difficult already. Second, we wanted to move to a database where we know it can handle large amounts of data in the long run. This benefits the Cloud Product as well as self-hosters which have high scalability requirements.
- **Move to an OLAP database**: From the requirements, it becomes apparent, that we need an OLAP database in our stack in the long run. We evaluated only databases, which are free to use for self-hosters as we did not want to make a requirement to run on any cloud provider. When looking at the options, there is mostly Clickhouse, Druid and Pinot. There are many blog articles by large tech companies using one of the three. We eventually decided to go with Clickhouse mostly because it fits our requirements and we made our POCs work. On top, and know many fellow founders and engineers who work with Clickhouse and advised us to go with it.


When talking to other companies, we learned that Clickhouse is a popular choice these days for analytical workloads. Many modern observability tools, such as [Signoz](https://signoz.io/) or [Posthog](https://posthog.com/), as well as established companies like [Cloudflare](https://blog.cloudflare.com/http-analytics-for-6m-requests-per-second-using-clickhouse/), use Clickhouse for their analytical workloads.

We observed that many modern observability tools, such as Signoz, highlight.io, and Posthog, as well as established companies like Cloudflare, use Clickhouse for their analytical workloads. This influenced our decision to adopt Clickhouse, as it offers a scalable solution for both our needs and those of our OSS self-hosters. Finally, we were looking for a solution which is scalable long term to prevent multiple database migrations for us and our self-hosting users.

Implications of adding Clickhouse for self-hosting users:
- We will provide clear guidelines and tooling to migrate from Postgres to Clickhouse.
- We will provide guidelines on when to use which Clickhouse deployment option.
- For all deployment options, we will automate as much as possible (e.g. upgrades, backups).

## Technical details
### SDK compatibility

<Callout type="warning">
  Cloud users: SDK versions below 2.0.0 need to be upgraded until Nov. 10th, 2024.
</Callout>

Langfuse V3 is not completely backwards compatible with our SDKs on versions below 2.0.0. Please upgrade and benefit from many performance improvements or features such as [prompt caching](https://langfuse.com/changelog/2024-02-05-sdk-level-prompt-caching).


**Upgrade options**:
- Default SDK upgrade: We wrote documentation on how to upgrade from 1.x.x to 2.x.x ([Python](https://langfuse.com/docs/sdk/python/low-level-sdk#upgrading-from-v1xx-to-v2xx), [JS](https://langfuse.com/docs/sdk/typescript/guide#upgrade1to2)). For the JS SDK, we also have an upgrade path [from 2.x.x to 3.x.x](https://langfuse.com/docs/sdk/typescript/guide#upgrade2to3). The upgrade is straightforward and should not take much time.
- Improved integrations: Since the first major version, we built many new ways to integrate your code with Langfuse such as [Decorators](https://langfuse.com/docs/sdk/python/decorators) for Python. We would recommend to check out our [quickstart](https://langfuse.com/docs/get-started) to see whether there is a more convenient integration available for you.


**Background**: Langfuse V3 relies on an event driven backend architecture. This means, that we acknowledge HTTP requests from the SDKs, queue the HTTP bodies in the backend, and process them asynchronously. This allows us to scale the backend more easily and handle more requests without overloading the database. The SDKs below 2.0.0 send the events to our server and expect a synchronous response containing the database representation of the event. If you rely on this data and access it in the code, your SDK will break as of Nov. 11th, 2024.

### Event Backups in Cloud Storage

In addition to storing events in the database, you may want to store a backup of all raw incoming events in a cloud storage bucket.
Use the `LANGFUSE_S3_EVENT_UPLOAD_*` environment variables to coxnfigure this.

| Environment Variable                         | Description                                                                   | Example                                    |
| -------------------------------------------- | ----------------------------------------------------------------------------- | ------------------------------------------ |
| `LANGFUSE_S3_EVENT_UPLOAD_ENABLED`           | Enable raw event uploads to cloud storage                                     | `true`                                     |
| `LANGFUSE_S3_EVENT_UPLOAD_BUCKET`            | The bucket that should store raw events                                       | `my-bucket`                                |
| `LANGFUSE_S3_EVENT_UPLOAD_PREFIX`            | (optional) Prefix to use within the bucket. Must end with `/` if provided.    | `events/`                                  |
| `LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT`          | (optional) API endpoint to use. Must be S3 compatible.                        | `s3.us-east-1.amazonaws.com`               |
| `LANGFUSE_S3_EVENT_UPLOAD_REGION`            | (optional) Region to use.                                                     | `us-east-1`                                |
| `LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID`     | (optional) Access key id to use. Falls back to standard credential chain.     | `AKIAIOSFODNN7EXAMPLE`                     |
| `LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY` | (optional) Access key secret to use. Falls back to standard credential chain. | `wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY` |


